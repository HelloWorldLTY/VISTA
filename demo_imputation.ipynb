{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5558632f-1b46-43a7-b952-1cba3b349d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import numpy as np\n",
    "import scanpy\n",
    "import scanpy as sc\n",
    "from scipy.stats import spearmanr\n",
    "from imputevi import GIMVI_GCN\n",
    "import scvi\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random \n",
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13840ee-d585-49da-a250-5f32198bfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scipy.stats as st\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe472c01-3d97-4ac8-8c98-e3d6410f5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_pse_correlation(adata_sc, adata_st, celltype, p_value_threshold = 0.05, cor_threshold = 0.5):\n",
    "    overlap_gene = overlap_gene = list(set(adata_sc.var_names).intersection(adata_st.var_names))\n",
    "    adata_sc = adata_sc[:,overlap_gene]\n",
    "    adata_st = adata_st[:,overlap_gene]\n",
    "    \n",
    "    cell_type_common = list(set(adata_sc.obs[celltype].unique()).intersection(adata_st.obs[celltype].unique()))\n",
    "    \n",
    "    pseudo_st = []\n",
    "    pseudo_sc = []\n",
    "    for i in cell_type_common:\n",
    "        adata1 = adata_st[adata_st.obs[celltype] == i]\n",
    "        adata2 = adata_sc[adata_sc.obs[celltype] == i]\n",
    "\n",
    "        pseudo_st.append(np.mean(adata1.X.toarray(), axis = 0))\n",
    "        pseudo_sc.append(np.mean(adata2.X.toarray(), axis = 0))\n",
    "    \n",
    "    pseudo_st = np.array(pseudo_st)\n",
    "    pseudo_sc = np.array(pseudo_sc)\n",
    "\n",
    "    cor_pearson = []\n",
    "    cor_pvalue = []\n",
    "    for i in range(pseudo_st.shape[1]):\n",
    "        cor, pval = st.pearsonr(pseudo_st[:,i], pseudo_sc[:,i])\n",
    "        cor_pearson.append(cor)\n",
    "        cor_pvalue.append(pval)\n",
    "        \n",
    "    information_stat = pd.DataFrame()\n",
    "\n",
    "    information_stat['pearson'] = cor_pearson\n",
    "    information_stat['pvalue'] = cor_pvalue\n",
    "    information_stat.index = adata_st.var_names\n",
    "\n",
    "    information_stat_update = information_stat.loc[((information_stat['pvalue']<p_value_threshold) & (information_stat['pearson']>cor_threshold))]\n",
    "    \n",
    "    return information_stat_update.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ad6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/scrnaseq_data.h5ad\")\n",
    "spatial_data = sc.read_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/spatial_data.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b26e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data.obs['names'] = seq_data.obs_names\n",
    "spatial_data.obs['names'] = spatial_data.obs_names\n",
    "\n",
    "seq_data.obs['ind_x'] = seq_data.obs_names\n",
    "spatial_data.obs['ind_x'] = spatial_data.obs_names\n",
    "\n",
    "spatial_index = [list(spatial_data.obs['x_coord']), list(spatial_data.obs['y_coord'])]\n",
    "spatial_data.obsm['spatial'] = np.array(spatial_index).T.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d9a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gene = calcualte_pse_correlation(seq_data, spatial_data, 'scClassify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7740c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(2023)\n",
    "gene_for_impute = seq_data.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e764ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = seq_data[:,gene_for_impute]\n",
    "spatial_data = spatial_data[:,info_gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b0bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/scvi/data/_utils.py:172: UserWarning: Category 0 in adata.obs['_scvi_ind_x'] has fewer than 3 cells. Models may not train properly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spatial_data_partial = spatial_data.copy()\n",
    "seq_data = seq_data.copy()\n",
    "\n",
    "seq_gene_names = seq_data.var_names\n",
    "n_genes = seq_data.n_vars\n",
    "\n",
    "# spatial_data_partial has a subset of the genes to train on\n",
    "spatial_data_partial = spatial_data_partial\n",
    "\n",
    "# # remove cells with no counts\n",
    "# scanpy.pp.filter_cells(spatial_data_partial, min_counts=1)\n",
    "# scanpy.pp.filter_cells(seq_data, min_counts=1)\n",
    "\n",
    "# setup_anndata for spatial and sequencing data\n",
    "GIMVI_GCN.setup_anndata(spatial_data_partial, batch_key=\"batch\", obs_names = 'names')\n",
    "GIMVI_GCN.setup_anndata(seq_data)\n",
    "# GIMVI.setup_anndata(seq_data, labels_key=\"graph_cluster_anno\")\n",
    "\n",
    "# spatial_data should use the same cells as our training data\n",
    "# cells may have been removed by scanpy.pp.filter_cells()\n",
    "spatial_data = spatial_data[spatial_data_partial.obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6538082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GIMVI_GCN(seq_data, spatial_data_partial, n_latent = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe05d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b341ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.8 /gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/l ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python3.8 /gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/l ...\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200:   6%|â–‹         | 13/200 [00:25<05:49,  1.87s/it, loss=3.37e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gibbs/project/zhao/tl688/conda_envs/scgpt/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# train for 200 epochs\n",
    "model.train(200)\n",
    "\n",
    "fish_imputation_norm = model.get_imputed_values(normalized=True)[0]\n",
    "fish_imputation_raw = model.get_imputed_values(normalized=False)[0]\n",
    "fish_imputation_theta = model.get_imputed_theta(normalized=False)[0]\n",
    "\n",
    "spatial_data_imputed = sc.AnnData(fish_imputation_raw, obs = spatial_data_partial.obs, var = seq_data.var)\n",
    "\n",
    "spatial_data_imputed.obsm['imputed'] = fish_imputation_norm\n",
    "spatial_data_imputed.obsm['imputed_raw'] = fish_imputation_raw\n",
    "spatial_data_imputed.obsm['imputed_raw_theta'] =  fish_imputation_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30c61df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial_data_imputed.write_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish_cluster/gimvigcn_smfish_allgenes_best.h5ad\")\n",
    "spatial_data_imputed.write_h5ad(\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish_cluster/gimvigcn_smfish_allgenes_mode200.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b581f-bb99-42bf-ba7a-4fa116599983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb6f7519",
   "metadata": {},
   "source": [
    "# Uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b466260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty.scvi_distribution import NegativeBinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d32a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6197ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cossim(A,B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd62754",
   "metadata": {},
   "source": [
    "# for cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "\n",
    "adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat32_nei20sc_ep400_smfish_seed0.h5ad\")\n",
    "# adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat64_nei20_ep200_smfish_seed{seed}.h5ad\")\n",
    "import random \n",
    "random.seed(2023)\n",
    "adata.layers['imputed_raw'] = adata.obsm['imputed_raw']\n",
    "adata.layers['imputed_raw_theta'] = adata.obsm['imputed_raw_theta']\n",
    "\n",
    "adata_st_true = adata[:, test_g]\n",
    "adata_st_raw = adata_st[:, test_g]\n",
    "\n",
    "distr = NegativeBinomial(mu = torch.FloatTensor(adata_st_true.layers['imputed_raw']), \n",
    "                         theta = torch.FloatTensor(adata_st_true.layers['imputed_raw_theta']))\n",
    "\n",
    "sample_200 = []\n",
    "sample_0_1 = int(min(100, len(adata)*0.1))\n",
    "for _ in range(sample_0_1):\n",
    "    sample_200.append(distr.sample())\n",
    "\n",
    "cossim_mean = []\n",
    "for cell in range(0,len(adata_st_true)):\n",
    "    cossim_store = []\n",
    "    for item in range(sample_0_1):\n",
    "        sample_data = sample_200[item]\n",
    "        cossim_store.append(cossim(sample_data, adata_st_true.layers['imputed_raw'][cell,:]))\n",
    "    cossim_mean.append(np.median(cossim_store))\n",
    "\n",
    "median_upper = np.argsort(cossim_mean)[0:int(len(adata_st_true)//2)]\n",
    "\n",
    "print(len(median_upper))\n",
    "\n",
    "# adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat64_nei20_ep200_smfish_seed{seed}.h5ad\")\n",
    "adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat32_nei20sc_ep400_smfish_seed0.h5ad\")\n",
    "\n",
    "adata.X = adata.obsm['imputed_raw']\n",
    "adata = adata[adata_st_raw.obs_names,:]\n",
    "adata_st_true = adata[median_upper,:]\n",
    "print(adata_st_true) # final reliable result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06ad05",
   "metadata": {},
   "source": [
    "# for gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f04945",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat32_nei20sc_ep400_smfish_seed0.h5ad\")\n",
    "import random \n",
    "random.seed(2023)\n",
    "adata.layers['imputed_raw'] = adata.obsm['imputed_raw']\n",
    "adata.layers['imputed_raw_theta'] = adata.obsm['imputed_raw_theta']\n",
    "\n",
    "adata_st_true = adata[:, test_g]\n",
    "adata_st_raw = adata_st[:, test_g]\n",
    "\n",
    "distr = NegativeBinomial(mu = torch.FloatTensor(adata_st_true.layers['imputed_raw']), \n",
    "                         theta = torch.FloatTensor(adata_st_true.layers['imputed_raw_theta']))\n",
    "\n",
    "sample_200 = []\n",
    "sample_0_1 = int(min(100, len(adata)*0.1))\n",
    "for _ in range(sample_0_1):\n",
    "    sample_200.append(distr.sample())\n",
    "\n",
    "cossim_mean = []\n",
    "for gene in range(0,len(test_g)):\n",
    "    cossim_store = []\n",
    "    for item in range(sample_0_1):\n",
    "        sample_data = sample_200[item][:,gene]\n",
    "        cossim_store.append(cossim(sample_data, adata_st_true.layers['imputed_raw'][:,gene]))\n",
    "    cossim_mean.append(np.mean(cossim_store))\n",
    "\n",
    "median_upper = np.argsort(cossim_mean)[::-1][0:int(len(test_g)//2)] # can control the length by modifying this upper bound\n",
    "\n",
    "print(median_upper)\n",
    "\n",
    "\n",
    "adata = sc.read_h5ad(f\"/gpfs/gibbs/pi/zhao/tl688/tangram/data_smfish/gimvigat_lat32_nei20sc_ep400_smfish_seed0.h5ad\")\n",
    "\n",
    "adata.X = adata.obsm['imputed_raw']\n",
    "adata_st_true = adata[:, test_g]\n",
    "adata_st_true = adata_st_true[:,median_upper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782313d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edaebd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
